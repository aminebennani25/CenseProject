{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:11:18.410088Z",
     "start_time": "2020-03-05T20:11:18.392101Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T12:34:20.016626Z",
     "start_time": "2020-03-05T12:34:19.905027Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "file_path = '.\\TUT-acoustic-scenes-2017-development.meta\\TUT-acoustic-scenes-2017-development\\evaluation_setup'\n",
    "fold1 = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:44:08.324935Z",
     "start_time": "2020-03-05T21:44:08.205852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 has 3510 sounds to train\n"
     ]
    }
   ],
   "source": [
    "train1 = os.path.join(file_path,fold1[2])\n",
    "fold1_filename = []\n",
    "fold1_label = []\n",
    "with open(train1, 'r') as f:\n",
    "    data = f.readlines()  #data reading line by line\n",
    "    for line in data:\n",
    "        record = line.split()        #split the filename and label\n",
    "        fold1_filename.append(record[0][6:])\n",
    "        fold1_label.append(record[1])\n",
    "print('fold 1 has {} sounds to train'.format(len(fold1_filename)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because training set is too large, so we take first 100 songs for testing our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T00:24:58.146265Z",
     "start_time": "2020-03-05T00:24:57.395002Z"
    }
   },
   "outputs": [],
   "source": [
    "# audio = []\n",
    "# for root,dirnames,filenames in os.walk('./'):\n",
    "#     for filename in filenames:\n",
    "#         f = os.path.join(root, filename)\n",
    "#         if f.endswith('.wav'):\n",
    "#             audio.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:44:13.916220Z",
     "start_time": "2020-03-05T21:44:13.723340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small training test has 1000 data\n",
      "Small training test label has 1000 records\n",
      "There are 15 classes in the training data\n"
     ]
    }
   ],
   "source": [
    "audio = []\n",
    "\n",
    "indices = np.arange(len(fold1_filename))\n",
    "np.random.shuffle(indices)\n",
    "n_sound = 1000\n",
    "indices = indices[:n_sound]\n",
    "fold1_filename_small = np.array(fold1_filename)[indices]\n",
    "fold1_label_small = np.array(fold1_label)[indices]\n",
    "\n",
    "for root,dirnames,filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "         if filename in fold1_filename_small:\n",
    "            f = os.path.join(root, filename)\n",
    "            audio.append(f)\n",
    "print(f'Small training test has {len(audio)} data')\n",
    "print(f'Small training test label has {len(audio)} records')\n",
    "classes = set(fold1_label_small)\n",
    "n_classes = len(classes)\n",
    "print(f'There are {n_classes} classes in the training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:44:16.782250Z",
     "start_time": "2020-03-05T21:44:16.768259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label list is the following:\n",
      "{'office': 0, 'residential_area': 1, 'library': 2, 'home': 3, 'beach': 4, 'forest_path': 5, 'metro_station': 6, 'car': 7, 'bus': 8, 'tram': 9, 'cafe/restaurant': 10, 'park': 11, 'city_center': 12, 'grocery_store': 13, 'train': 14}\n"
     ]
    }
   ],
   "source": [
    "dictionary = dict(zip(classes, list(np.arange(n_classes))))  # build the connection between labels and numbers\n",
    "print('label list is the following:')\n",
    "print(dictionary)\n",
    "temp=[]\n",
    "for label in fold1_label_small:\n",
    "    temp.append(dictionary[label])\n",
    "fold1_label_small = temp\n",
    "# print(fold1_label_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block for the first time to run this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T12:48:22.767840Z",
     "start_time": "2020-03-05T12:41:27.520266Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# M is a matrix who stores the infomation about each audio\n",
    "# Structure of matrix M: song stft rmse spec_cent spec_bw rolloff zcr mfcc(39 coef) label\n",
    "M = []\n",
    "\n",
    "for song,label in zip(audio,fold1_label_small):\n",
    "    y, sr = librosa.load(song, mono=True, duration=5) \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc[1:]:  # delete the first coefficient\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    to_append += f' {label}'\n",
    "    M.append(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:22:40.188794Z",
     "start_time": "2020-03-05T20:22:40.097424Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('M.npy',M)   # 6 min to load 1000 sound files\n",
    "M = np.load('M.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:11:29.012683Z",
     "start_time": "2020-03-05T20:11:28.875766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 26)\n"
     ]
    }
   ],
   "source": [
    "DATA_train= np.zeros((n_sound,26))\n",
    "for i in range(n_sound):\n",
    "    DATA_train[i,:] = np.array(M[i].split(' '))\n",
    "print(DATA_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:17:22.450100Z",
     "start_time": "2020-03-05T20:17:22.437106Z"
    }
   },
   "outputs": [],
   "source": [
    "X = DATA_train[:,:-1]    #  25 coefficients which define the caracteristics of each sound\n",
    "y = DATA_train[:,-1].astype(np.int32)   # last column is label\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Normalie each column of X, which means each dimension\n",
    "# Convert class vector y to binary class matrices, in one-hot form\n",
    "X_train, y_train = preprocessing.scale(X),keras.utils.to_categorical(y, n_classes)  \n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:19.809184Z",
     "start_time": "2020-03-05T21:40:19.707138Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras import metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(n_features,)))\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:20.196149Z",
     "start_time": "2020-03-05T21:40:20.189152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 32)                832       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 15)                495       \n",
      "=================================================================\n",
      "Total params: 1,327\n",
      "Trainable params: 1,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()   # The model is complex for the dataset or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:17:57.762706Z",
     "start_time": "2020-03-05T20:17:57.751712Z"
    }
   },
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred): # correlation coefficient\n",
    "    a = K.square(y_pred - y_true)\n",
    "    b = K.sum(a)\n",
    "    c = K.mean(y_true)\n",
    "    d = K.square(y_true - c)\n",
    "    e = K.sum(d)\n",
    "    f = 1 - b/e\n",
    "    return f\n",
    "def precision_top_k(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:31.497322Z",
     "start_time": "2020-03-05T21:40:31.267304Z"
    }
   },
   "outputs": [],
   "source": [
    "# opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "opt = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[precision_top_k])    # metrics.categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:35.439816Z",
     "start_time": "2020-03-05T21:40:31.801231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 2.8471 - precision_top_k: 0.3290\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.6966 - precision_top_k: 0.3990\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.6318 - precision_top_k: 0.4670\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.5927 - precision_top_k: 0.5200\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 2.5588 - precision_top_k: 0.5670\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.5304 - precision_top_k: 0.5630\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 2.5087 - precision_top_k: 0.5730\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 2.4828 - precision_top_k: 0.5980\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.4672 - precision_top_k: 0.6010\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 2.4463 - precision_top_k: 0.6130\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 2.4213 - precision_top_k: 0.6220\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.4074 - precision_top_k: 0.6370\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.3836 - precision_top_k: 0.6400\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 2.3699 - precision_top_k: 0.6420\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.3537 - precision_top_k: 0.6630\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 2.3341 - precision_top_k: 0.6720\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.3146 - precision_top_k: 0.6800\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.3125 - precision_top_k: 0.6850\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.2903 - precision_top_k: 0.6780\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.2702 - precision_top_k: 0.6900\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(X_train,y_train,epochs=20,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:18:56.305323Z",
     "start_time": "2020-03-05T20:18:56.204311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 has 1170 documents to test\n"
     ]
    }
   ],
   "source": [
    "test1 = os.path.join(file_path,fold1[0])\n",
    "fold1_filename = []\n",
    "fold1_label = []\n",
    "with open(test1, 'r') as f:\n",
    "    data = f.readlines()  #data reading line by line\n",
    " \n",
    "    for line in data:\n",
    "        record = line.split()        #split the filename and label\n",
    "        fold1_filename.append(record[0][6:])\n",
    "        fold1_label.append(record[1])\n",
    "print('fold 1 has {} documents to test'.format(len(fold1_filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:24:02.304599Z",
     "start_time": "2020-03-05T20:24:02.152693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 1170 records\n",
      "There are 15 classes in the test set\n"
     ]
    }
   ],
   "source": [
    "audio = []\n",
    "\n",
    "for root,dirnames,filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "         if filename in fold1_filename:\n",
    "            f = os.path.join(root, filename)\n",
    "            audio.append(f)\n",
    "\n",
    "print(f'Test set has {len(audio)} records')\n",
    "classes = set(fold1_label)\n",
    "n_classes = len(classes)\n",
    "print(f'There are {n_classes} classes in the test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:19:45.578160Z",
     "start_time": "2020-03-05T20:19:45.573165Z"
    }
   },
   "outputs": [],
   "source": [
    "temp=[]\n",
    "for label in fold1_label:\n",
    "    temp.append(dictionary[label])\n",
    "fold1_label= temp\n",
    "# print(fold1_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block for the first time to run this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:37:38.689965Z",
     "start_time": "2020-03-05T20:28:58.597464Z"
    }
   },
   "outputs": [],
   "source": [
    "# M is a matrix who stores the infomation about each audio\n",
    "# Structure of matrix M: song stft rmse spec_cent spec_bw rolloff zcr mfcc(39 coef) label\n",
    "\n",
    "M_test = []\n",
    "\n",
    "for song in audio:\n",
    "    y, sr = librosa.load(song, mono=True, duration=5) \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc[1:]:  # delete the first coefficient\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    M_test.append(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:37:50.443207Z",
     "start_time": "2020-03-05T20:37:50.353649Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('M.npy',M_test)   # 8min 40s\n",
    "M_test = np.load('M.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T20:41:55.965152Z",
     "start_time": "2020-03-05T20:41:55.875207Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_test = np.zeros((1170,25))\n",
    "for i in range(1170):\n",
    "    DATA_test[i,:] = np.array(M_test[i].split(' '))\n",
    "X_test = DATA_test\n",
    "y_test = np.array(fold1_label)\n",
    "X_test, y_test = preprocessing.scale(X_test),keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:44.207173Z",
     "start_time": "2020-03-05T21:40:43.584559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_5_categorical_accuracy on test set is 36.41025641025641 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "label_pred = np.argsort(y_pred,axis=1)[:,-5:]  # top_5_categorical_accuracy  shape:1170*5\n",
    "label_true = np.array(fold1_label)\n",
    "acc=0\n",
    "for i in range(1170):\n",
    "    a = label_true[i]\n",
    "    b = label_pred[i,:]\n",
    "    acc+=np.isin(a,b,invert=False)\n",
    "print('top_5_categorical_accuracy on test set is {} %'.format(acc*100/1170))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T21:40:46.914895Z",
     "start_time": "2020-03-05T21:40:46.368236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170/1170 [==============================] - 0s 206us/step\n",
      "Test loss: 3.0875690248277454\n",
      "Test_acc: 36.41025722026825 %\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print(f'Test_acc: {100*test_acc} %') # Low test accuracy less than training data accuracy indicating Overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
